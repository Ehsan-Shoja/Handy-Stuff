{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O'Reilly's Hands-On Machine Learning\n",
    "\n",
    "This is a summary of O'Reilly's Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow by Aurélien Géron.\n",
    "\n",
    "It is intended for educational purposes and to aid in recalling key concepts from the book. While this summary can serve as a helpful resource, particularly for those already familiar with machine learning concepts, reading the full book is recommended for a deeper and more comprehensive understanding.\n",
    "\n",
    "Compiled By: [Ehsan Shoja](https://github.com/Ehsan-Shoja)\n",
    "\n",
    "[Amazon Link](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1098125975/ref=sr_1_1?dib=eyJ2IjoiMSJ9.0Jm1bLoXUBA_cK-tar7HW1L7KzUCRFLa7mcRAFq-rLTy9PEEcfbJngB3j_3uBdmXAbwWBS7I-Kqi_atom4RZU0Y1xye91MLl2TdyDVE4Kf8l0woo02WSfml0mcQS9Kng0Z1MByj7BO6420rod2hLJXz_V7DYEZCSQsolJGvkH3S9dpanNESObVQXSzEmsqvSUe9E3cADzok_s-6YKiHEjlZbkIaoIenfvpU8C2JNWWY.6EzVvN3KT6UkEwbAuKmINWOtFcbxhk6ZMQtYOse71hg&dib_tag=se&keywords=Hands-Machine-Learning-Scikit-Learn-Tensorflow&qid=1727339966&sr=8-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Key Terms from the Chapter\n",
    "\n",
    "- **Training Set**: The dataset used by the system to learn.\n",
    "- **Training Instance (or Sample)**: Each individual example in the training set.\n",
    "- **Model**: The part of the machine learning system responsible for learning and making predictions.\n",
    "- **Data Mining**: The process of discovering hidden patterns in large datasets, where machine learning excels.\n",
    "- **Regression**: A task that involves predicting a continuous value.\n",
    "- **Classification**: A task focused on predicting discrete outputs, such as True or False.\n",
    "- **Clustering**: Grouping input data without predefined labels.\n",
    "- **Hierarchical Clustering**: Subdividing groups into smaller, more specific clusters.\n",
    "- **Feature**: A specific attribute or property of the input data.\n",
    "- **Target**: The output in a regression task.\n",
    "- **Label**: The output in a classification task.\n",
    "- **Transfer Learning**: The practice of transferring knowledge from one task to another, especially useful in deep learning (i.e., neural networks with many layers).\n",
    "- **Offline Learning (Batch Learning)**: Training the model first, then using the trained model for predictions.\n",
    "- **Online Learning**: Continuously training the model as new data comes in.\n",
    "- **Out-of-Core Learning**: Training models on datasets that are too large to fit in memory. This is usually done incrementally and offline.\n",
    "- **Learning Rate (in Online Learning)**: A parameter that defines how quickly the model should adapt to new data.\n",
    "- **Utility Function (or Fitness Function)**: A function that measures how well the model is performing.\n",
    "- **Cost Function**: A function that measures how poorly the model is performing.\n",
    "- **Inference**: Using the trained model to make predictions on new data.\n",
    "- **Feature Engineering**: The process of refining and improving the input data to enhance model performance.\n",
    "- **Feature Selection**: Identifying and selecting the most important and relevant features for model training.\n",
    "- **Feature Extraction**: Transforming or combining existing features into more useful ones.\n",
    "- **Regularization**: A technique used to constrain a model and make it simpler, reducing the risk of overfitting.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning has been around for decades, initially applied in specialized fields like **optical character recognition (OCR)**, which allows machines to convert images of text into machine-readable text. One of the earliest mainstream machine learning applications was the **spam filter**, popularized in the 1990s to classify emails as spam or ham (non-spam). Since then, ML has expanded into various other applications, including:\n",
    "\n",
    "- **Voice prompts** (e.g., virtual assistants like Siri or Alexa)\n",
    "- **Automatic translation** (e.g., Google Translate)\n",
    "- **Image search** (e.g., recognizing and searching for objects in images)\n",
    "- **Product recommendations** (e.g., personalized suggestions on e-commerce platforms like Amazon)\n",
    "\n",
    "These applications highlight the growing role of machine learning in everyday technology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Is Machine Learning?**\n",
    "\n",
    "Machine learning is the science (and art) of programming computers to learn from data, allowing systems to improve their performance without being explicitly programmed for each task. In essence, rather than relying on a fixed set of instructions, the machine learns patterns from data and adapts.\n",
    "\n",
    "A more general definition was given by Arthur Samuel in 1959:\n",
    "> “Machine learning is the field of study that gives computers the ability to learn without being explicitly programmed.”\n",
    "\n",
    "This captures the core idea: computers can improve at tasks by learning from experience, much like humans do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is a training set?**\n",
    "\n",
    "The **training set** is the collection of examples that the machine learning system uses to learn. It is the dataset that the model is trained on to discover patterns and relationships in the data.\n",
    "\n",
    "**What is a training instance?**\n",
    "\n",
    "Each individual example in the training set is called a **training instance** (or sample). It represents a single data point or input that the model uses to learn from.\n",
    "\n",
    "**What is a model?**\n",
    "\n",
    "A **model** is the part of a machine learning system responsible for learning from the training set and making predictions. Examples of models include **neural networks**, **random forests**, and **linear regression models**. The model identifies patterns in the training data and uses these learned patterns to make predictions on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model has three components:\n",
    "\n",
    "1.    T (Task) – The task the model is used for.\n",
    "2.    E (Experience) – The training data used to learn from.\n",
    "3.    P (Performance) – The performance measure used to evaluate the model, which depends on the type of machine learning application. For example, in classification tasks, this is typically called accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A comparison is made between **traditional programming** and **machine learning (ML)** models for spam detection. Traditional programming requires explicitly defining a large set of rules, which is time-consuming and complex. In contrast, an ML model learns from data, offering the potential for greater accuracy. Additionally, traditional programming is harder to maintain, as it demands frequent updates to accommodate new spam patterns, while ML models adapt automatically as they are exposed to new data.\n",
    "\n",
    "Another area where **machine learning** shines is in tackling problems that are too complex for traditional approaches or have no known algorithm, such as **speech recognition**. Machine learning also uncovers patterns and hidden information that might otherwise be missed.\n",
    "\n",
    "**What is data mining?**\n",
    "\n",
    "Digging into large amounts of data to discover hidden patterns is called **data mining**, and machine learning excels at this. \n",
    "\n",
    "To summarize, **machine learning** is particularly effective for:\n",
    "\n",
    "- Problems where existing solutions require extensive fine-tuning or long lists of rules (an ML model can simplify code and outperform traditional approaches)\n",
    "- Complex problems where traditional methods fail to provide effective solutions (ML techniques can potentially find new solutions)\n",
    "- Fluctuating environments (ML models can be easily retrained on new data, keeping them up-to-date)\n",
    "- Gaining insights into complex problems and analyzing large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image classification (CNN, Transformers): Analyzing images of products on a production line to automatically classify them, can be done either by Convolutional neural network (CNN, chap 14) or transformers (chap 16)\n",
    "\n",
    "Semantic image segmentation (CNN, Transformers): Detecting tumors in brain scans, each pixel in the image is classified (as we want to determine the exact location and shape of tumors), typically using CNNs or transformers.\n",
    "\n",
    "Natural language processing (NLP)/ text classification (RNN, CNN, Transformers): Automatically classifying news articles, Automatically flagging offensive comments on discussion forums, Summarizing long documents automatically, Creating a chatbot or a personal assistant, can be tackled using recurrent neural networks (RNNs) and CNNs, but transformers work even better (see Chapter 16). there are NLP components for these task such as natural language understanding (NLU) and question-answering modules.\n",
    "\n",
    "Regression task: Forecasting your company’s revenue next year, based on many performance metrics, linear regression or polynomial regression model (see Chapter 4), a regression support vector machine (see Chapter 5), a regression random forest (see Chapter 7), or an artificial neural network (see Chapter 10). If you want to take into account sequences of past performance metrics, you may want to use RNNs, CNNs, or transformers (see Chapters 15 and 16)\n",
    "\n",
    "Speech recognition (CNN, Transformers): Making your app react to voice commands, requires processing audio samples: since they are long and complex sequences, they are typically processed using RNNs, CNNs, or transformers (see Chapters 15 and 16)\n",
    "\n",
    "Anomaly detection (GMM, autoencoders): Detecting credit card fraud, can be tackled using isolation forests, Gaussian mixture models (see Chapter 9), or autoencoders (see Chapter 17)\n",
    "\n",
    "Clustering (k-means, DBSCAN): Segmenting clients based on their purchases so that you can design a different marketing\n",
    "strategy for each segment, can be achieved using k-means, DBSCAN, and more (see Chapter 9)\n",
    "\n",
    "Data visualization (dimensionality reduction,): Representing a complex, high-dimensional dataset in a clear and insightful diagram\n",
    "\n",
    "Recommender system (ANN): Recommending a product that a client may be interested in, based on past purchases, One approach is to feed past purchases (and other information about the client) to an artificial neural network (see Chapter 10), and get it to output the most likely next purchase. This neural net would typically be trained on past sequences of purchases across all clients.\n",
    "\n",
    "Reinforcement learning: Building an intelligent bot for a game, a branch of machine learning that trains agents (such as bots) to pick the actions that will maximize their rewards over time (e.g., a bot may get a reward every time the player loses some life points), within a given environment (such as the game). The famous AlphaGo program that beat the world champion at the game of Go was built using RL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of Applications\n",
    "\n",
    "- **Image Classification (CNN, Transformers)**: Analyzing products on a production line to automatically classify them. This task is typically performed using Convolutional Neural Networks (CNNs) or transformers (see Chapters 14 and 16).\n",
    "\n",
    "- **Semantic Image Segmentation (CNN, Transformers)**: Detecting tumors in brain scans by classifying each pixel in the image to determine the exact location and shape of the tumor. CNNs or transformers are commonly used.\n",
    "\n",
    "- **Natural Language Processing (NLP)/Text Classification (RNN, CNN, Transformers)**: Tasks such as automatically classifying news articles, flagging offensive comments, summarizing documents, or creating chatbots. Recurrent Neural Networks (RNNs), CNNs, and transformers (Chapter 16) are used for these tasks, often utilizing modules like Natural Language Understanding (NLU) and question-answering systems.\n",
    "\n",
    "- **Regression Tasks**: Forecasting a company’s revenue based on past performance metrics. This can be tackled using linear regression, polynomial regression (Chapter 4), regression support vector machines (Chapter 5), random forests (Chapter 7), or artificial neural networks (Chapter 10). For sequence data, RNNs, CNNs, or transformers may be better suited (Chapters 15 and 16).\n",
    "\n",
    "- **Speech Recognition (CNN, Transformers)**: Enabling applications to respond to voice commands by processing complex audio sequences. This is done using RNNs, CNNs, or transformers (Chapters 15 and 16).\n",
    "\n",
    "- **Anomaly Detection (GMM, Autoencoders)**: Detecting anomalies such as credit card fraud using isolation forests, Gaussian Mixture Models (GMM, Chapter 9), or autoencoders (Chapter 17).\n",
    "\n",
    "- **Clustering (K-Means, DBSCAN)**: Segmenting clients based on their purchasing behavior to customize marketing strategies. This can be achieved using k-means, DBSCAN, or similar clustering algorithms (Chapter 9).\n",
    "\n",
    "- **Data Visualization (Dimensionality Reduction)**: Simplifying and representing complex, high-dimensional datasets through dimensionality reduction techniques for clear, insightful visualizations.\n",
    "\n",
    "- **Recommender Systems (ANN)**: Suggesting products to clients based on past purchases. This can be accomplished by feeding previous purchase data into an Artificial Neural Network (ANN, Chapter 10) to predict future preferences.\n",
    "\n",
    "- **Reinforcement Learning (RL)**: Training intelligent agents or bots, such as a game-playing bot that optimizes its actions to maximize rewards. AlphaGo, which famously defeated the world champion in Go, used RL for decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Machine Learning Systems\n",
    "\n",
    "Machine learning systems can be categorized in multiple ways. Each system falls into one category from the following groups:\n",
    "\n",
    "**Category 1: Supervision Type**\n",
    "- **Supervised**: The model is trained on labeled data (input-output pairs).\n",
    "- **Unsupervised**: The model is trained on unlabeled data, aiming to find hidden patterns.\n",
    "- **Semi-supervised**: A mix of a small amount of labeled data and a large amount of unlabeled data.\n",
    "- **Self-supervised**: A specific case of supervised learning where labels are generated from the data itself.\n",
    "- **Other types**: Include reinforcement learning, where agents learn by interacting with an environment.\n",
    "\n",
    "**Category 2: Learning Style**\n",
    "- **Online Learning**: The model learns incrementally, processing data as it arrives.\n",
    "- **Batch Learning**: The model is trained on the entire dataset at once.\n",
    "\n",
    "**Category 3: Generalization Approach**\n",
    "- **Instance-based**: The system learns by comparing new data to known instances (e.g., k-nearest neighbors).\n",
    "- **Model-based**: The system builds a general model from the data and makes predictions based on that model.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category One: Training Supervision\n",
    "\n",
    "### Supervised Learning\n",
    "\n",
    "In supervised learning, the model is provided with both input data (features) and the corresponding desired output—either a **target** in the case of regression or a **label** in classification tasks. The model learns to map the input to the output.\n",
    "\n",
    "### Unsupervised Learning\n",
    "\n",
    "Unsupervised learning only uses input data, with no labels or targets. The model tries to find patterns or relationships within the data. Common tasks include:\n",
    "\n",
    "- **Clustering**: Grouping data based on similarities (e.g., customer segmentation).\n",
    "- **Dimensionality Reduction**: Simplifying data by reducing the number of features while retaining meaningful information. For instance, merging car mileage and age into a single feature representing \"wear and tear.\"\n",
    "- **Anomaly Detection**: Identifying unusual or rare data points, useful for fraud detection or fault detection.\n",
    "- **Association Rule Learning**: Discovering interesting relationships between variables in large datasets (e.g., market basket analysis).\n",
    "\n",
    "Unsupervised learning can also involve **visualization algorithms**, like t-SNE, which highlight patterns or clusters in data by projecting high-dimensional data into lower dimensions.\n",
    "\n",
    "- **Anomaly Detection vs. Novelty Detection**: \n",
    "  - **Anomaly detection** finds unusual data points, whether known or unknown anomalies.\n",
    "  - **Novelty detection** focuses on identifying completely new, unexpected behaviors by recognizing deviations from the normal patterns learned during training.\n",
    "\n",
    "For better performance and efficiency, reducing the number of dimensions can lower computational costs and memory usage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Sources/Figure 1-7. An unlabeled training set for unsupervised learning.png\" alt=\"Figure 1-7. An unlabeled training set for unsupervised learning\" width=\"500\" height=\"300\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Sources/Figure 1-8. Clustering.png\" alt=\"Figure 1-8. Clustering\" width=\"500\" height=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Sources/Figure 1-9. Example of a t-SNE visualization highlighting semantic clusters.png\" alt=\"Figure 1-11. Semi-supervised learning with two classes\" width=\"500\" height=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Semi-Supervised Learning\n",
    "\n",
    "In semi-supervised learning, the dataset contains a small amount of labeled data and a large amount of unlabeled data. The model aims to predict labels for the unlabeled data by leveraging the available labeled data. Many semi-supervised algorithms combine supervised and unsupervised techniques.\n",
    "\n",
    "For example, a clustering algorithm may group similar instances together, and then each unlabeled instance can be assigned the most common label in its cluster. Once the entire dataset is labeled, standard supervised learning methods can be applied.\n",
    "\n",
    "**Example**: Google Photos uses semi-supervised learning to organize and label images by combining some labeled data with unlabeled images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Sources/Figure 1-11. Semi-supervised learning with two classes.png\" alt=\"Figure 1-11. Semi-supervised learning with two classes\" width=\"500\" height=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Self-Supervised Learning\n",
    "\n",
    "Self-supervised learning involves generating labels from an entirely unlabeled dataset. Once labels are generated, the model can be trained using supervised learning techniques. \n",
    "\n",
    "In this approach, a portion of the data is intentionally masked or removed, and the modified data is used as input while the original data serves as the target. The model is then trained to predict the missing information. Successful reconstruction indicates that the model has learned important patterns and relationships in the data. After this pretraining phase, the model can be applied to other tasks, such as classification, by fine-tuning it on a labeled dataset.\n",
    "\n",
    "This process often involves **transfer learning**, where the knowledge gained from one task is transferred to another. Transfer learning, especially in deep neural networks (which have many layers), is a key technique in modern machine learning and will be covered in more detail later.\n",
    "\n",
    "While self-supervised learning uses unlabeled data, it differs from unsupervised learning (which includes tasks like clustering and dimensionality reduction) because it generates labels, bringing it closer to supervised learning. Due to this unique nature, it is best considered its own category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Reinforcement Learning\n",
    "\n",
    "In reinforcement learning, an agent learns by interacting with an environment. The algorithm receives **rewards** for correct actions or decisions and **penalties** for incorrect ones. The goal is to maximize cumulative rewards over time by improving the decision-making process.\n",
    "\n",
    "The strategy the model follows to make decisions is called a **policy**. The policy determines the best action to take in a given situation to maximize rewards. See Figure 1-13 for a visual representation of how reinforcement learning works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Sources/Figure 1-13. Reinforcement learning.png\" alt=\"Figure 1-13. Reinforcement learning\" width=\"500\" height=\"300\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category two: Batch Versus Online Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline learning / Batch learning:\n",
    "\n",
    "In this approach, the model is trained on the entire dataset at once, and the fully trained model is then used in applications. However, because it does not learn incrementally, its performance will degrade over time—a phenomenon known as model rot or data drift. The rate of decay depends on the task. For example, a model classifying cats and dogs may degrade more slowly compared to a model predicting stock prices.\n",
    "\n",
    "As a result, all models, even a cat classifier, need to be re-trained eventually (e.g., if people start dressing their pets in new ways). Re-training involves training the model from scratch on a dataset that includes both old and new data. As shown in Figure 1-3, this process can be automated, but it can also be time-consuming and resource-intensive, which is especially problematic for tasks like stock price prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Sources/Figure 1-3. Automatically adapting to change.png\" alt=\"Figure 1-3. Automatically adapting to change\" width=\"500\" height=\"300\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Re-training requires significant computational resources, making it a challenge. An alternative approach to this is online learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Learning\n",
    "\n",
    "Online learning trains a system incrementally by feeding it data sequentially, either one instance at a time or in small mini-batches. Each learning step is quick and efficient, allowing the system to adapt to new data in real-time.\n",
    "\n",
    "- It enables rapid adaptation to changes.\n",
    "- Suitable for limited computing resources.\n",
    "- Can handle large datasets that don’t fit in memory (out-of-core learning), by loading and processing data in chunks until complete.\n",
    "\n",
    "The learning rate determines how fast the system adapts:\n",
    "- A high learning rate quickly adapts but forgets old data.\n",
    "- A low learning rate provides stability but reacts slower and is less affected by noise or outliers.\n",
    "\n",
    "A key challenge is performance decay when bad data is introduced. To mitigate this, monitor the system, disable learning if necessary, and use anomaly detection for abnormal data inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category three: Instance-Based Versus Model-Based Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance-Based Learning\n",
    "\n",
    "Instance-based learning involves memorizing examples and generalizing to new cases based on their similarity to the stored examples. In the context of a spam filter, instead of just flagging identical emails, the system could flag emails that are similar to known spam. A basic similarity measure could be the number of shared words between emails.\n",
    "\n",
    "This approach classifies new data by comparing it to stored instances and applying a similarity measure to make predictions. For example, if most similar instances are flagged as spam, the new instance would also be flagged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-Based Learning and Typical Machine Learning Workflow\n",
    "\n",
    "In model-based learning, the system builds a model from data and uses it to make predictions. For example, to study if money affects happiness, we could model life satisfaction as a linear function of GDP per capita, using parameters θ0 and θ1 to represent the relationship.\n",
    "\n",
    "#### Steps in Model-Based Learning:\n",
    "1. **Data Collection**: Gather data (e.g., GDP per capita and life satisfaction for different countries).\n",
    "2. **Model Selection**: Choose a model, such as a linear regression.\n",
    "3. **Training**: Run an algorithm to find the best parameters (θ0 and θ1) by minimizing a cost function (e.g., the difference between predictions and actual data).\n",
    "4. **Prediction**: Apply the trained model to make predictions on new data.\n",
    "\n",
    "#### Example:\n",
    "Using a linear regression model (Equation 1-1), we can predict Cyprus’s life satisfaction from its GDP per capita. If Cyprus’s GDP per capita is $37,655, the model estimates life satisfaction around 6.30.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <img src=\"Sources/Equation 1-1. A simple linear model.png\" alt=\"Equation 1-1. A simple linear model\" width=\"250\" height=\"100\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple means, the model only has one feature, is first polynomial degree. by finding the best theta parameters we can fit best model to out dataset. finally the model predict from this Equation. to find the best value for parameters, cost function is used which measures the distance between the linear model’s predictions and the training examples; the objective is to minimize this distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.30165767]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Download and prepare the data\n",
    "data_root = \"https://github.com/ageron/data/raw/main/\"\n",
    "lifesat = pd.read_csv(data_root + \"lifesat/lifesat.csv\")\n",
    "X = lifesat[[\"GDP per capita (USD)\"]].values\n",
    "y = lifesat[[\"Life satisfaction\"]].values\n",
    "# Visualize the data\n",
    "lifesat.plot(kind='scatter', grid=True,\n",
    "x=\"GDP per capita (USD)\", y=\"Life satisfaction\")\n",
    "plt.axis([23_500, 62_500, 4, 9])\n",
    "plt.show()\n",
    "# Select a linear model\n",
    "model = LinearRegression()\n",
    "# Train the model\n",
    "model.fit(X, y)\n",
    "# Make a prediction for Cyprus\n",
    "X_new = [[37_655.2]] # Cyprus' GDP per capita in 2020\n",
    "print(model.predict(X_new)) # output: [[6.30165767]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for instance based you can use k-nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.33333333]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=3)\n",
    "# Train the model\n",
    "model.fit(X, y)\n",
    "# Make a prediction for Cyprus\n",
    "X_new = [[37_655.2]] # Cyprus' GDP per capita in 2020\n",
    "print(model.predict(X_new)) # output: [[6.30165767]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Workflow:\n",
    "1. Study the data.\n",
    "2. Select and train a model.\n",
    "3. Evaluate predictions (inference).\n",
    "4. Refine the model if necessary.\n",
    "\n",
    "This process defines a typical machine learning workflow, which you will practice in detail in later chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you are not satisfied you always can use more complex models (e.g., a polynomial regression model) or more features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Challenges of Machine Learning\n",
    "\n",
    "the two things that can go wrong are “bad model” and “bad data”. Let’s start with examples of bad data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insufficient Quantity of Training Data**: While more data generally leads to better model performance, the claim that simple models can perform as well as complex ones is not always correct. This depends heavily on the task at hand. For example, in NLP (natural language processing), even so-called \"simple\" models, like Naive Bayes, are still relatively complex compared to something like linear regression. You can’t expect a simple model like linear regression to outperform a large neural network on complex tasks. Moreover, the advantage of more data is most evident with very large datasets, not with medium-sized ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nonrepresentative Training Data**: The book refers to this term in two scenarios. First, when the dataset is too small, it may fail to capture the full complexity of the task. For instance, with more data, it may become apparent that a simple linear model isn’t suitable for certain tasks. The second scenario involves **sampling bias**. For example, if data is collected through a survey targeting a specific group of people, the result could be biased and unrepresentative of the broader population. This bias can lead to misleading conclusions and prevent the model from generalizing well to all groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Poor-Quality Data**: Sometimes the dataset collected contains bad or corrupted data. For example, if you're gathering temperature data from a weather station and the sensor is broken, it may record outliers or fail to capture data. In such cases, the model will optimize its weights based on incorrect or poor-quality data, leading to a poorly performing model that fails to generalize well. The book advises addressing these issues before training the model by cleaning the data—removing outliers or filling in missing values using methods like the median or average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Irrelevant Features**: Machine learning models try to find patterns in input data without understanding the actual relevance of features. For example, a student's favorite color has no logical connection to their math scores, but if such irrelevant data is provided, the model may still attempt to relate it, leading to poor results. The book introduces the concept of **feature engineering**, which involves refining and improving the data input to the model. This includes:\n",
    "\n",
    "- **Feature selection**: Identifying and selecting the most useful features for training.\n",
    "- **Feature extraction**: Combining or transforming existing features to create more meaningful ones, sometimes with the help of dimensionality reduction techniques.\n",
    "- **Creating new features**: Gathering additional data to generate new, potentially more relevant features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have looked at many examples of bad data, let’s look at a couple examples of bad algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overfitting the Training Data**: Overfitting occurs when a model is too complex and performs very well on the training data but struggles to generalize to new, unseen samples. The model essentially memorizes the training data, leading to errors when dealing with new inputs. The book uses an analogy: if you take a taxi in a new city and the driver is rude, you might wrongly conclude that all drivers in that city have bad attitudes. Similarly, a curvy regression model might fit the training data perfectly, but a small deviation in new data could result in a large prediction error due to the model's complexity.\n",
    "\n",
    "To address overfitting, you can either:\n",
    "- **Simplify the model**: Reducing the model's complexity by removing unnecessary parts.\n",
    "- **Use regularization**: Regularization helps find a balance by keeping some complexity while preventing overfitting. It works by adding a penalty term to the model, which discourages it from becoming too complex.\n",
    "\n",
    "Regularization is controlled by a **hyperparameter**, a constant that we set manually. Unlike model parameters (which the algorithm learns), hyperparameters are tuned by the user and are critical to building an effective machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Underfitting the Training Data**: Underfitting happens when a model is too simple to capture the underlying patterns in the data. As a result, it performs poorly even on the training data. For instance, using a linear model to predict life satisfaction can lead to underfitting because life satisfaction is influenced by complex factors, and a simple model won't be able to capture these complexities.\n",
    "\n",
    "To address underfitting, you can:\n",
    "- **Select a more powerful model**: Use a model with more parameters that can better capture the complexity of the data.\n",
    "- **Improve feature engineering**: Provide better or more relevant features to the model to enhance its learning.\n",
    "- **Reduce model constraints**: For instance, by lowering the regularization hyperparameter, you allow the model to fit the data more freely without overly penalizing complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stepping Back\n",
    "\n",
    "After covering many machine learning concepts, it's helpful to revisit the big picture:\n",
    "\n",
    "- **Machine Learning** focuses on making machines improve at tasks by learning from data, rather than being explicitly programmed with rules.\n",
    "- **Types of ML Systems**: There are various kinds of machine learning systems, such as supervised or unsupervised, batch or online learning, and instance-based or model-based systems.\n",
    "- In an **ML project**, you gather a training set and feed it to a learning algorithm. A **model-based** algorithm adjusts parameters to fit the model to the training data, aiming to generalize well to new data. An **instance-based** algorithm memorizes examples and generalizes by comparing new instances to the stored examples using a similarity measure.\n",
    "- The system's performance depends on the quality of the data and the model. A small, unrepresentative, noisy, or irrelevant dataset will lead to poor outcomes (\"garbage in, garbage out\"). Additionally, the model needs to be balanced: neither too simple (which causes underfitting) nor too complex (which causes overfitting). \n",
    "\n",
    "This recap ties together the fundamental concepts of ML, ensuring you focus on data quality and the right balance of model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Validating \n",
    "\n",
    "When building a machine learning model, you can’t rely on intuition to gauge its performance—objective measures are needed to assess how well the model generalizes and how accurate it is. This is done through **testing and validating** by splitting the available data into two parts: a **train set** and a **test set**. As the names suggest, the train set is used to build the model, while the test set contains unseen data used to evaluate the model’s performance.\n",
    "\n",
    "The error measured on the test set is called the **generalization error** or **out-of-sample error**, which reflects how well the model performs on new, unseen data. A typical split is 80% for training and 20% for testing, but this can vary, especially with large datasets where a 99% to 1% split might suffice.\n",
    "\n",
    "While this gives a basic understanding, there’s much more to model validation, such as **cross-validation**, which the book introduces later. Cross-validation helps in assessing model performance more robustly by repeatedly splitting the data and averaging the results to reduce variability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Hyperparameter Tuning and Model Selection \n",
    "\n",
    "Initially, we split the dataset into a training set and a test set, but this approach has a limitation. Suppose you're trying to choose between models, each with different hyperparameters (e.g., regularization). If you train and evaluate each model using the test set, the model may perform well on both the training and test sets but fail to generalize to new, unseen data. This happens because you've effectively adapted the model to the test set.\n",
    "\n",
    "To avoid this, it's recommended to use an additional split called a **validation set** (also called the development or dev set). The process involves training your model on the training set, tuning hyperparameters based on performance on the validation set, and repeating this until you find the best model. Once you have the model with the lowest validation error, you evaluate its generalization performance using the test set.\n",
    "\n",
    "However, there are potential issues with the validation set approach. If the validation set is too small, model evaluations can be inaccurate, leading to the selection of a suboptimal model. On the other hand, if the validation set is too large, the training set becomes smaller, and the final model (trained on the full dataset) may not reflect the models used during evaluation.\n",
    "\n",
    "To address this, **cross-validation** is used, where the data is split into multiple small validation sets. The model is trained and evaluated multiple times on different splits, and the performance is averaged. This provides a more accurate measure of model performance at the cost of increased training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Sources/Figure 1-25. Model selection using holdout validation.png\" alt=\"Figure 1-25. Model selection using holdout validation\" width=\"500\" height=\"300\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Data Mismatch\n",
    "\n",
    "**Data mismatch** occurs when the information we collect for training a model does not accurately represent the conditions or scenarios that the model will face in real-world applications. This can lead to significant performance issues. \n",
    "\n",
    "For example, in the book, the **flower picture** scenario illustrates this concept. When building an app that identifies flower species from photographs taken with a smartphone camera, developers might gather a vast number of flower images from the internet. However, these internet images can vary widely in resolution, size, lighting conditions, and angles, making them different from the pictures that users will actually take with the app. \n",
    "\n",
    "As a result, when we evaluate the model using a validation test, we cannot easily determine whether any errors are due to data mismatch (i.e., the training data not being representative of the real-world data) or overfitting (where the model performs well on training data but poorly on unseen data). \n",
    "\n",
    "To address this issue, Andrew Ng recommends creating a **train-dev set**, which consists of a subset of the training data that is representative of the actual use case. This train-dev set should be drawn from the same source as the training data (e.g., internet flower images) but set aside specifically for evaluation. \n",
    "\n",
    "If the model performs well on this train-dev set, we can conclude that overfitting is likely not the problem. We can then evaluate the model using the validation set, which should contain representative data for the task at hand. If the results are acceptable, we can move on to the test set to assess the model’s generalization error, which indicates how well the model is expected to perform on new, unseen data in production.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No Free Lunch (NFL) Theorem**\n",
    "\n",
    "The **No Free Lunch (NFL) Theorem** states that there is no universally superior model for all datasets; the best model depends on the specific data characteristics. Thus, practitioners must make reasonable assumptions and evaluate various models to find the most effective one for a given task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
